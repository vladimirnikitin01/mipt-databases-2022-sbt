# mipt-databases-2022-sbt_HW_4
## Отчет домашняя работа №4, Jackrabbit 

В данно домашей задаче нам надо разобраться с данной СУБД и подробно ответить на множество вопросов, которые помогут составить более подробное описание нашей СУБД. Давайте, начнем.

**a)История развития СУБД**

 хранилище содержимого с открытым исходным кодом для платформы Java. Проект Jackrabbit был начат 28 августа 2004 года (но первые идеи были еще в 2002), когда компания Day Software начала разработку реализации API хранилища содержимого для Java (JCR). Jackrabbit также был использован как пример реализации JSR-170 и JSR-283. Проект вышел из «инкубатора» Apache 15 марта 2006 года и сейчас является проектом верхнего уровня в Apache Software Foundation. Надо отметить, что примерно каждые 2 недели появляются новые выпуски, причем некоторые из них являются нестабильными или выпусками дополнительны функций, так что разработчики постоянно занимимаются расширением и улучшением нынешних версий. Последняя стабильная версия вышла 2 марта 2022 г.


[Загрузка и версии Apache Jackrabbit](https://jackrabbit.apache.org/jcr/downloads.html)

**b)Инструменты для взаимодействия с СУБД**

На официальном сайте написано следующее: разработчики используют различные инструменты для помощи в работе, такие как IntelliJ IDEA или Eclipse. Большинство инструментов не требуют указания атрибуции, но некоторые требуют (YourKit Java Profiler). Хотелось бы немного рассказать про каждую из выше перечисленных. [Eclipse](https://www.eclipse.org/) служит в первую очередь платформой для разработки расширений, чем он и завоевал популярность: любой разработчик может расширить Eclipse своими модулями. [IntelliJ IDEA](https://www.jetbrains.com/opensource/idea/) — интегрированная среда разработки программного обеспечения для многих языков программирования, в частности Java, JavaScript, Python, разработанная компанией JetBrains. [YourKit Java Profiler](https://www.yourkit.com/benefits/#:~:text=YourKit%20Java%20Profiler%20is%20the,simply%20unrivaled%20but%20absolutely%20unique.) — это ведущий инструмент профилирования на рынке Java, предоставляющий самые инновационные, мощные и интеллектуальные возможности анализа производительности.

**c)Какой database engine используется в вашей СУБД?**

Приложения контента взаимодействуют через API JSR-170 с реализацией репозитория контента. Существует множество приложений, доступных для репозиториев JSR-170, некоторые из них очень общие (например, сервер WebDAV), другие приложения могут быть очень специфичными и использовать репозиторий контента в качестве хранилища информации, используемой приложениями.Java-приложения могут использовать репозиторий содержимого JSR-170 в качестве замены чего угодно, от файлов свойств, XML-конфигурации, определенных частей функциональности реляционной базы данных до прямой файловой системы или управления большими двоичными объектами.

Репозиторий на основе контента — это иерархическое хранилище контента, в котором собраны структурированный и неструктурированный контент, полнотекстовый поиск, наблюдение за транзакциями управления версиями и многое другое.

![image](https://user-images.githubusercontent.com/58188954/166662155-21b750df-6b9a-4676-b70b-51b1542f27fc.png)

Также давайте более подробно рассмотрим [архитектуру](https://jackrabbit.apache.org/jcr/jackrabbit-architecture.html)

![image](https://user-images.githubusercontent.com/58188954/166662841-8c44eec7-0795-4637-bda4-2a8e0177129c.png)

**d)Как устроен язык запросов в вашей СУБД? Разверните БД с данными и выполните ряд запросов. **

Язык запросов - JCR (в примерах буду использовать именно его), также есть версии Jackrabbit для работы с JCR-SQL2(вот тут будет уже обычный удобный и привычный для синтаксис. 
Для начала для установки нам скачать [файлы](https://jackrabbit.apache.org/jcr/downloads.html) или можно установить через терминал (мы поступим именно так)![image](https://user-images.githubusercontent.com/58188954/166663782-944208f6-6235-496c-98b8-15e120db0858.png)

Как мы помним с самого начала, Jackrabbit является примером реализации jcr. Можно использовать удобные оболочки для работы с Jackrabbit, но можно писать команды и с помощью java, давайте рассмотрим самые базовые примеры.

*Создадим хранилище содержимого Jackrabbit и начнем сеанс входа в систему для доступа к нему.*

![image](https://user-images.githubusercontent.com/58188954/166677915-1ba07498-6ac7-48ad-bf5c-714833f7367f.png)

*Давайте покажем код для примера, когда мы будем сохранять "Hello, World!"+извлекать+удалять.*

![image](https://user-images.githubusercontent.com/58188954/166678578-0fd9257f-efe1-4940-b974-f2ace5800d97.png)

*Но понятно, что нам надо уметь загружать уже готовые данные, давайте создадим test.xml с рандомными числами (для этого подойдет python), а затем заимпортим данный файл*

![image](https://user-images.githubusercontent.com/58188954/166680061-3e62eef8-dd73-4afb-94f2-369fba68af58.png)

Также понятно, что из-за популярности и большой гибкости java мы можем делать почти любую обработку данных и другие манипуляции.
Хорошие примеры есть вот [тут](https://ru.bmstu.wiki/Apache_Jackrabbit#.D0.9D.D0.B0.D1.87.D0.B0.D0.BB.D0.BE_.D1.80.D0.B0.D0.B1.D0.BE.D1.82.D1.8B_.D1.81_Apache_Jackrabbit) и [тут](https://jackrabbit.apache.org/archive/wiki/JCR/ExamplesPage_115513397.html).


**e)Распределение файлов БД по разным носителям?**

На официальном сайте информации по этому вопросу не нашёл, но я нашел информацию насчет [CacheManager](https://jackrabbit.apache.org/archive/wiki/JCR/CacheManager_115513375.html).CacheManager управляет размером кешей, используемых в Jackrabbit. Общий размер всех кэшей должен быть ограничен, чтобы избежать проблем с нехваткой памяти. Без CacheManager у Jackrabbit может закончиться нехватка памяти, потому что объединенный размер различных кэшей не управляется. Этот механизм не является окончательным решением. Также максимальный размер всех кешей в CacheManager по умолчанию составляет 16 мегабайт, но его можно изменить. Доступная память динамически распределяется по кешам максимум каждую секунду. CacheManager пытается вычислить наилучшие размеры кэша, сравнивая количество обращений к каждому кэшу и используемую память. 

Таже я нашел [идейные будущие улучшения](https://jackrabbit.apache.org/archive/wiki/JCR/DataStore_115513387.html#DataStore-FutureIdeas), которые должны ускорить время работы, например "контент, к которому обращаются чаще, может быть перемещен на более быстрый диск, а менее используемые данные могут быть в конечном итоге перемещены на более медленный/дешевый диск. Это было бы расширением «иерархии памяти","ускорить сбор мусора. Одна из идей состоит в том, чтобы использовать «обратные ссылки» для более крупных объектов","автоматическое сжатие хранилища данных,если определенный тип содержимого и размер файла позволяют сэкономить много места на диске при сжатии"

**f)На каком языке/ах программирования написана СУБД?**

JAVA

**g)Какие типы индексов поддерживаются в БД? Приведите пример создания индексов.**

В данном пункте мы будем рассматривать [Jackrabbit Oak](https://jackrabbit.apache.org/oak/docs/) (это дополнительная реализация спецификации JCR).

Чтобы запросы выполнялись хорошо, Oak поддерживает индексирование контента, хранящегося в репозитории. Индексация работает путем сравнения различных версий данных узла (технически это «разница» между базовым NodeState и модифицированным NodeState ). Режим индексации определяет, как выполняется сравнение и когда обновляется содержимое индекса:
- Synchronous Indexing
- Asynchronous Indexing
- Near Real Time (NRT) Indexing
  
В настоящее время Oak имеет следующие встроенные редакторы:
- PropertyIndexEditor
- ReferenceEditor
- LuceneIndexEditor
- SolrIndexEditor

Но давайте вернемся к нашим режимам индексации, сначала я дам краткую информацию о каждом из данных реживо, а затем покажу универсальный код для создания индексации.
- Synchronous Indexing-при синхронном индексировании содержимое индекса обновляется как часть самой фиксации. Изменения как основного содержимого, так и содержимого индекса выполняются атомарно в одном коммите.
- Асинхронное индексирование (также называемое асинхронным индексированием) выполняется с помощью периодических запланированных заданий. В рамках установки Oak планирует определенные периодические задания, которые выполняют сравнение содержимого репозитория и обновляют содержимое индекса на основе этого.
- NRT IndexingИндексы. Lucene хорошо подходят для оценки сложных запросов и имеют то преимущество, что оцениваются локально с поддержкой копирования при чтении. Однако они асинхронны и в зависимости от загрузки системы могут отставать от состояния репозитория. В случаях, когда такое отставание (которое может составлять несколько минут) неприемлемо, необходимо использовать индексы свойств . Чтобы избежать этого, в Oak 1.6 добавлена ​​поддержка индексирования почти в реальном времени. ![image](https://user-images.githubusercontent.com/58188954/166704147-e8d88110-c00a-46ea-a517-2f1717f20028.png)


Теперь давайте приведу пример, как нам устанавливать нужный режим индексов

![image](https://user-images.githubusercontent.com/58188954/166705426-6a140813-7801-4cc4-84a7-fc33bf9c1d6b.png)
- type(It determines the type of index):reference(Configured with the out-of-the-box setup),counter(Configured with the out-of-the-box setup),property,lucene,solr.
- async(This determines if the index is to be updated synchronously or asynchronously):sync(It indicates that index is meant to be updated as part of each commit.),nrt(Indicates that index is a near real time index.),async(Indicates that index is to be updated asynchronously)

Также async можем задавать сразу параметров, особенно это актуально для [различных](https://jackrabbit.apache.org/oak/docs/query/indexing.html#nrt-indexing-usage) NRT режимов:
- NRT (Near real time)    ![image](https://user-images.githubusercontent.com/58188954/166715343-ffdfc824-9d93-46ce-947f-e30cc892b2f7.png)
- NRT Indexing Mode - nrt      ![image](https://user-images.githubusercontent.com/58188954/166715423-dc483f69-5243-48c8-8323-02398e591809.png)
- NRT Indexing Mode - sync       ![image](https://user-images.githubusercontent.com/58188954/166715485-ba0211ff-2939-43ad-8705-118350e3a56a.png)



**h)Как строится процесс выполнения запросов в вашей СУБД?**

В данном пункте мы снова продолжим работать с Jackrabbit Oak.

На официальном сайте есть даже отдельная [глава](https://jackrabbit.apache.org/oak/docs/query/query-engine.html), которая посвещена данному вопросу

Oak не индексирует столько контента по умолчанию, как Jackrabbit. При необходимости вам нужно создавать собственные индексы, как в традиционных СУБД. Если для конкретного запроса нет индекса, то репозиторий будет пройден. То есть запрос все равно будет работать, но, вероятно, будет очень медленным. 

Внутри обработчик запросов использует оптимизатор запросов на основе затрат, который запрашивает у всех доступных индексов запросов предполагаемую стоимость обработки запроса. Затем он использует индекс с наименьшей стоимостью. Также так как нам требуется высокая стоимость, но много где используется кэширование, если смотреть уже саму реализацию.
По умолчанию доступны следующие индексы:
* Индекс свойства для каждого проиндексированного свойства.
* Полнотекстовый индекс, основанный на Apache Lucene/Solr.
* Индекс типа узла (который основан на индексе свойства для свойств jcr:primaryType и jcr:mixins).
* Индекс обхода, который выполняет итерацию по поддереву.


Если ни один индекс не может эффективно обработать условие фильтра, узлы в репозитории просматриваются в заданном поддереве.

Обычно данные считываются из индекса и репозитория при просмотре результата запроса. Однако есть исключения, когда все данные считываются в память при выполнении запроса. Наиболее распространен случай, когда используется предложение order by , и индекс не может предоставить отсортированный результат. Есть и другие случаи, когда пути к уже прочитанным результатам хранятся в памяти, чтобы не возвращать повторяющиеся результаты. 

Теперь давайте поговорим немного более подробно насчет стоимости обработки запроса.

Мы можем довольно наглядно посмотреть стоимость запроса, если установим в режиме DEBUG org.apache.jackrabbit.oak.query, тогда вот данный код будет нам показывать стоимость соответствующих параметров.

![image](https://user-images.githubusercontent.com/58188954/166725256-869be881-5680-46c1-a8e5-fe408890008f.png)

Теперь немного поговорим насчет самого расчета стоимости: мы ожидаем, что каждый индекс запроса будет оценивать наихудшую стоимость запроса с заданным фильтром. Возвращаемое значение находится между 1 (очень быстро) и оценочным количеством записей, которые нужно пройти, если курсор будет полностью прочитан.Возвращаемое значение должно быть оценочным и не обязательно должно быть очень точным. Также этот метод вызывается для каждого индекса всякий раз, когда выполняется запрос, поэтому метод должен быть достаточно быстрым (не считывать данные сами по себе или, по крайней мере, не считывать слишком много данных). Поэтому обычно использует жадный алгоритм для обхода дерева.  Также если у нас происходит какая-то проблема при запросе данных, то мы возвращаем бесконечность (Double.POSITIVE_INFINITY)


**i)Есть ли для вашей СУБД понятие «план запросов»? Если да, объясните, как работает данный этап.**

Да, конечно есть такое понятие (причем его упоминают в официальной литературе, но без конкретики). На самом деле в интернете почти нет никакой информации насчет плана запросов в данной СУБД, но я нашел все же некоторые статьи, которые дают понимание, что у нас происходит. 

Обратимся к [статье](https://jackrabbit.apache.org/oak/docs/query/grammar-sql2.html), где перечислены все основновные команды запросов, а также обсудим в чем именно у нас проблема. План выполнения запроса — последовательность операций, необходимых для получения результата, понятно, что если нам приходит какой-то список последовательных команд(или даже одна, но трудоемкая задача), то нам необходимо оптимизировать все процессы. Именно поэтому в предыдущих пунктах мы писали про жадные алгоритмы или кэширования, но теперь давайте перечислим (из официального сайта), то что мы требуем, чтобы план запросов мог хорошо по итогу оптимизировать свою работу.
- Все запросы должны иметь ограничение пути (даже если это просто, например, «/content»), так как это позволяет сжимать индексы.
- «distinct» гарантирует, что каждая строка возвращается только один раз.
- «union» объединяет результат этого запроса с результатами другого запроса, где «объединение всех» не удаляет дубликаты. Обратите внимание, что для полнотекстовых запросов использовать объединение проблематично, поскольку оценка производится для каждого подзапроса в отдельности. Оценка бесполезна для сравнения результатов различных подзапросов, поэтому объединение нескольких полнотекстовых запросов не будет упорядочено по оценке, как можно было бы ожидать.
- «order by» может использовать индекс. Если индекса для данного порядка сортировки нет, то результат полностью считывается в память и сортируется перед возвратом первой строки.

Таже если внимательно почитать статью, которую я указывал выше, там есть информация, как происходит оптимизация запросов. Также в статьях говорится, что происходят оптимизации при работе с памятью, но об этом я писал еще в одних из самых первых пунктов. К сожалению, никакой более конкретной ифнормации нигде нет.



**j)Поддерживаются ли транзакции в вашей СУБД? Если да, то расскажите о нем. Если нет, то существует ли альтернатива?**
Да, причем поддержка транзакций пришла еще в Jackrabbit еще 2006 году.

Говорится на [stackoverflow](https://stackoverflow.com/questions/18601405/how-do-i-use-jackrabbit-when-it-is-part-of-a-global-transaction), что мы можем настроить транзакции XA с помощью Jackrabbit.

Также транзакции, охватывающие несколько операций Session.save(), обрабатываются альтернативной ветвью сохраненных версий. Вместо того, чтобы делать сохраненную версию глобально доступной в качестве последней версии рабочей области, она остается локальной для транзакции. Когда транзакция зафиксирована, все ревизии в ветке транзакции объединяются в одну черновую ревизию, которая затем сохраняется в обычном режиме, как описано выше.

![image](https://user-images.githubusercontent.com/58188954/166746299-9088ea48-bfc9-474b-b3b5-4df4d5a6001b.png)


Если объединенная ревизия не может быть сохранена (что приводит к сбою фиксации) или если транзакция явно откатывается, то ревизии в ветви транзакции отбрасываются.


**k)Какие методы восстановления поддерживаются в вашей СУБД. Расскажите о них.**

На официальном сайте написано только про то, что модель ревизии позволяет «отмотать» репозиторий или рабочую область назад к предыдущему моменту времени без полного восстановления из резервных копий. Это позволяет очень легко и эффективно отменять такие операции, как случайное удаление больших частей репозитория.

Также конечно у нас есть горячее и инкрементное резервное копирование,давайте опишем прицип их работы:
Реализация горячего резервного копирования почти тривиальна, поскольку сохраненные версии никогда не изменяются. Таким образом, инструмент резервного копирования может просто скопировать сохраненные версии, даже если созданный ими репозиторий все еще работает.

После создания полной резервной копии репозитория или рабочей области необходимо копировать только новые файлы ревизий, чтобы резервная копия всегда была актуальной. Если ревизии хранятся в виде файлов на диске, то можно использовать стандартные инструменты, такие как rsync , для поддержки добавочного горячего резервного копирования репозитория.


**l)Расскажите про шардинг в вашей конкретной СУБД. Какие типы используются? Принцип работы.**
На самом деле по поиску данной темы снова ничего дельного не нашлось, кроме упоминания, что оно есть. А именно  на официальном сайте говорится, что Oak BlobStore похож на хранилище данных Jackrabbit 2.x. Однако есть несколько незначительных проблем, которые пытается решить BlobStore:
- sharding is slow
- the FileDataStore still doesn’t support sharding the directory currently

Так что получается, что шардинг, видимо, есть, но реализован он так себе. Причем на одной странице [форума](https://lists.apache.org/thread/tc0l1q5vw3njqysbx037h1z1z8lmjojf) был дан комментарий "Шардинг на основе пути в настоящее время не реализован", данный комментарий был 2017 года, но в комментариях к новым релизам нет упоминания изменений в данном направлении. 


**m)Возможно ли применить термины Data Mining, Data Warehousing и OLAP в вашей СУБД?**

На официальном сайте нет никакой информации, но мне кажется, что из-за построения нашей структуры Data Warehousing нельзя употреблять (так как у нас нет как минимум проблемно-предметная ориентации данных). OLAP и Data Mining у нас есть,об этом говорится на форумах и также прикладывали вот такой код:

![image](https://user-images.githubusercontent.com/58188954/166804093-f1cd6fe8-7f5a-4527-b0c0-e46c8169a430.png)



**n)Какие методы защиты поддерживаются вашей СУБД? Шифрование трафика, модели авторизации и т.п.**

Тут есть отдельная [статья](https://jackrabbit.apache.org/oak/docs/security/introduction.html) по данной теме. 

Основной точкой входа в систему безопасности Oak является SecurityProvider , который регистрируется в репозитории Oak при создании. Поставщик отвечает за сбор и предоставление всех модулей, связанных с безопасностью, присутствующих в данном репозитории Oak.

Каждый модуль безопасности поставляется с одной или несколькими конфигурациями безопасности , зарегистрированными у провайдера, идентифицированными (и, возможно, агрегированными) по их имени.

![image](https://user-images.githubusercontent.com/58188954/166811789-8e84bba2-0e41-48d5-94ff-64b6bc82f759.png)
![image](https://user-images.githubusercontent.com/58188954/166811832-51de0f0b-871a-40a6-a59c-3ff007120b58.png)

